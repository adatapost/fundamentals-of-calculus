%%chapter%% 08
<%
  require "./scripts/eruby_util.rb"
%>

<%
  chapter(
    '08',
    %q{The integral},
    'ch:integral'
  )
%>

<% begin_sec("The accumulation of change",nil,'accumulation') %>
  <% begin_sec("Change that accumulates in discrete steps",nil,'discrete-sums') %>
    <% begin_sec("A schoolboy plays a trick",nil,'schoolboy-trick') %>
Toward the end of the eighteenth century, a German elementary school teacher
decided to keep his pupils busy by assigning them a long, boring arithmetic
problem: to add up all the numbers
from one to a hundred.\footnote{I'm giving my own retelling of a hoary legend. We don't really know the exact problem, just that it was
supposed to have been something of this flavor.}
% http://www.americanscientist.org/issues/pub/gausss-day-of-reckoning#
 The children set to work on their slates, and the teacher
lit his pipe, confident of a long break. But almost immediately, a boy named
Carl Friedrich Gauss brought up his answer: 5,050.\label{gauss-story}\index{Gauss, Carl Friedrich}

<% marg(-17) %>
<%
  fig(
    'gauss-square',
    %q{Adding the numbers from 1 to 7.}
  )  
%>
\spacebetweenfigs
<%
  fig(
    'gauss-solution',
    %q{A trick for finding the sum.}
  )  
%>
\spacebetweenfigs
<%
  fig(
    'gauss',
    %q{Carl Friedrich Gauss (1777-1855), a long time after graduating from elementary school.}
  )  
%>
<% end_marg %>

Figure \figref{gauss-square} suggests one way of solving this type of problem.
The filled-in columns of the graph represent the numbers from 1 to 7, and
adding them up means finding the area of the shaded region. Roughly half the
square is shaded in, so if we want only an approximate solution, we can
simply calculate $7^2/2=24.5$.

But, as suggested in figure \figref{gauss-solution}, it's not much more work to
get an exact result. There are seven sawteeth sticking out out above the diagonal,
with a total area of $7/2$, so the total shaded area is $(7^2+7)/2=28$.
In general, the sum of the first $n$ numbers will be $(n^2+n)/2$, which explains
Gauss's result: $(100^2+100)/2=5,050$.

There is a tantalizing hint here of a link with differential calculus, because the
derivative of a real function $f(n)=(n^2+n)/2$ is almost, but not quite, equal to $n$.
    <% end_sec('schoolboy-trick') %>

    <% begin_sec("Accumulation of change in discrete steps",nil,'discrete-accumulation') %>

Problems like this come up frequently. Imagine that each household in a certain
small town sends a total of one ton of garbage to the dump every year. Over
time, the garbage accumulates in the dump, taking up more and more space.
If the population is constant, then
garbage accumulates at a constant rate.
But maybe the town's population is growing. If the population starts out
as 1 household in year 1, and then grows to 2 in year 2, and so on, then
we have the same kind of problem that the young Gauss solved. After 100
years, the accumulated amount of garbage will be 5,050 tons. The pile of
refuse grows more quickly every year.
    <% end_sec('discrete-accumulation') %>

    <% begin_sec("Sigma notation",nil,'sigma-notation') %>
There is a convenient way of notating sums like the ones we've been doing,
which involves $\Sigma$, called ``sigma,'' the capital Greek letter ``S.''
Here the ``S'' stands for ``sum.'' The sigma notation looks like this:
\begin{equation}\label{eqn:sigma-notation}
  \sum_{i=1}^{100} \; i = 5,050
\end{equation}
This is read as ``the sum of $i$ for $i$ from 1 to 100 equals 5,050.''
The version without the sigma notation is much more cumbersome to write:
\begin{equation}\label{eqn:no-sigma-notation}
  1+2+3+\ldots+100 = 5,050
\end{equation}
In equation \eqref{eqn:sigma-notation}, $i$ is a dummy variable. We could have written
\begin{equation*}
  \sum_{j=1}^{100} \; j = 5,050
\end{equation*}
and it would have meant exactly the same thing.
We've already seen some examples of dummy variables. In set notation (box \figref{sets}, p.~\pageref{fig:sets}),
\begin{equation*}
 \zu{S}=\{x|x^2>0\} \quad \text{and} \quad \zu{T}=\{y|y^2>0\}
\end{equation*}
describe exactly the same set, and S=T. Similarly, the function $f$ defined by $f(u)=u^2$ and the function
$g$ defined by $g(v)=v^2$ are the same function, $f=g$.
    <% end_sec('sigma-notation') %>
  <% end_sec('discrete-sums') %>

  <% begin_sec("The area under a graph",nil,'area-under-a-graph') %>
    <% begin_sec("The geometrical problem",nil,'area-under-a-graph-geom') %>
The examples in section \ref{subsec:discrete-sums} involved change that occurred in discrete
steps. Calculus is concerned with \emph{continuous} change. The continuous analog of
a discrete sum is the area under a graph.
Let $f$ be a function that is defined on an interval\footnote{For
interval notation, see p.~\pageref{interval-notation}.} $[a,b]$
and assume the value of $f$ is always positive (so that its graph lies above
the $x$ axis). \emph{How large is the area of the region caught
  between the $x$ axis, the graph of $y=f(x)$ and the vertical lines
  $y=a$ and $y=b$?}
    <% end_sec('area-under-a-graph-geom') %>
  <% end_sec('area-under-a-graph') %>
<% marg(0) %>
<%
  fig(
    'riemann-portrait',
    %q{Bernhard Riemann (1826-1866).}
  )  
%>
<% end_marg %>

<%
  fig(
    'area-under-graph',
    %q{1.~The area under the graph of the function $f$. 2.~Approximating this area using 20 thin rectangles.},
    {
      'width'=>'wide',
      'sidecaption'=>false
    }
  )
%>

  <% begin_sec("Approximation using a Riemann sum",nil,'riemann-sum') %>

We can try to compute this area, figure \figref{area-under-graph}{1}, by approximating
the region with many thin rectangles, \figref{area-under-graph}{2}.  The idea is that
even though we don't know how to compute the area of a region bounded
by arbitrary curves, we do know how to find the area of one or more
rectangles. In this example, we've subdivided the interval from $a$ to $b$
into $n=20$ equal subintervals, each of width $\Delta x=(b-a)/n$.
Let's write $x_1$ for the $x$ value that lies in the center of the first
subinterval, etc.
We've chosen the height of each rectangle so that its top intersects the
graph at this midpoint, so that, e.g., the height of the first rectangle
is $f(x_1)$.
The area of the $k^{\textrm{th}}$ rectangle is the product of its
height and width, which is $f(x_k)\Delta x$.  Adding up all the rectangles'
areas yields
\begin{equation}\label{eqn:riemann-sum}
  R = \sum_{k=1}^n f(x_k)\Delta x \qquad .
\end{equation}
This is an example of what is called a \emph{Riemann sum}, meaning an approximation
to the area under a curve using rectangles. This particular type of Riemann sum
is one in which (a) the interval is subdivided into equal parts, and (b) the value
of the function is sampled at the center of each subinterval.

If $f$ is negative in certain places, then
we will hit certain values of $k$ for which the product $f(x_k)\Delta x$ is negative.
We will simply \emph{define} areas below the $x$ axis to be negative. We think of
the rectangle as having positive width $\Delta x$ but negative height $f(x_k)$. A similar
geometrical example is the use of negative numbers for angles that are directed contrary
to a standard direction of rotation.

If our rectangles are all sufficiently narrow then we expect the total
area of all the rectangles to be a good approximation of the area of the region
under the graph.
  <% end_sec('riemann-sum') %>
<% end_sec('accumulation') %>

<% begin_sec("The definite integral",nil,'definite-integral') %>
  <% begin_sec("Definition of the integral of a continuous function",nil,'integral') %>
This suggests the following definition.

\begin{important}[Definition of the integral of a continuous function]
  If $f$ is a continuous function defined on an interval $[a, b]$, then
  the integral of $f(x)$ from $x=a$ to $b$ is defined as
  \begin{equation*}
    \lim_{\Delta x\rightarrow 0} R \qquad ,
  \end{equation*}
  where $R$ is the type of Riemann sum defined above, using equal subintervals
  sampled at their centers.
\end{important}

<%
  fig(
    'visualize-riemann-integral',
    %q{Three Riemann sums for the same function on the same interval. As $\Delta x$ approaches zero,
       the total area approaches
       the Riemann integral.},
    {
      'width'=>'wide',
      'sidecaption'=>false
    }
  )
%>

Up until now we've been doing differential calculus. The other half of calculus,
integral calculus, consists of the study of integrals. The type of integral defined
here is called a definite integral. We'll see later that there is another type, called
the indefinite integral.

<%
  fig(
    'riemann-triangle-area',
    %q{Example \ref{eg:riemann-triangle-area}.},
    {
      'width'=>'wide',
      'sidecaption'=>false
    }
  )
%>

\begin{eg}{A triangle}\label{eg:riemann-triangle-area}
Let $f(x)=x$. Then the integral of $f$ from $0$ to $1$ represents the area of a triangle
with height 1 and a base of width 1. We know from elementary geometry that this shape has
an area equal to $\frac{1}{2}(\text{base})(\text{height})=\frac{1}{2}$, so we don't need
integral calculus to determine it. But let's see how this works
out if we do it as an integral, in order to get comfortable with the tool and see if it
works in a case where we already know the answer.

When we split up the interval $[0,1]$ into $n$ parts, we have $\Delta x=1/n$.
The first subinterval is $[0,\Delta x$], and its center is
the first sample point, $x_0=(1/2)\Delta k$. Continuing in this way, we have
$x_k=(k-1/2)\Delta x$, for $k$ running from 1 to $n$. Since our function is just
$f(x)=x$, we also have $f(x_k)=(k-1/2)\Delta x$. 
The Riemann sum $R$ is shown in figure \figref{riemann-triangle-area}. It looks
almost exactly like the staircase in \figref{gauss-square} on
p.~\pageref{fig:gauss-square}. There are two differences: (1) in the
original staircase problem, the graph covered a
region of graph paper $n$ squares wide and $n$ squares tall, whereas the graph of our
Riemann sum is scaled down so that it fits inside  a single
 square with a width of 1 and a height of 1; (2) all of the steps have been lowered by
half a step.

When we evaluate the Riemann sum, we find that the fates have been kind to us, and
its value in this example always seems to be $1/2$, for every $n$. For example, with $n=3$ the Riemann sum is 
$\frac{1}{6}\Delta x+\frac{1}{2}\Delta x+\frac{5}{6}\Delta x=\frac{9}{6}\Delta x=\frac{1}{2}$.

To see that this is always true in this example, let's go ahead and compute the Riemann sum
for an arbitrary $n$.
\begin{align*}
  R &= \sum_{k=1}^n f(x_k)\Delta x \\
    &= \sum_{k=1}^n [(k-\frac{1}{2})\Delta x]\Delta x \\
    &= (\Delta x)^2 \sum_{k=1}^n \left(k-\frac{1}{2}\right) \\
    &= (\Delta x)^2 \left\{\left[\sum_{k=1}^n k\right] -\left[\sum_{k=1}^n \frac{1}{2}\right]\right\} \\
    &= (\Delta x)^2 \left\{\left[\sum_{k=1}^n k\right] -\frac{n}{2}\right\}
\end{align*}
The sum inside the square brackets is the same one that we encountered in our previous study of the
``staircase'' sum; it equals $(n^2+n)/2$. The result is:
\begin{align*}
  R &= (\Delta x)^2 \left\{\left[\frac{n^2+n}{2}\right] -\frac{n}{2}\right\} \\
    &= (\Delta x)^2 \frac{n^2}{2}
\end{align*}
But $\Delta x=1/n$, so $R=1/2$ exactly for every $n$, and
the integral equals
\begin{equation*}
  \lim_{n\rightarrow\infty} R = \frac{1}{2} \qquad ,
\end{equation*}
as expected geometrically.
\end{eg}
  <% end_sec('integral') %>

  <% begin_sec("Leibniz notation",nil,'integral-leibniz') %>
If we substitute equation \eqref{eqn:riemann-sum}
into the definition of the integral $\lim_{\Delta x\rightarrow 0} R$, the result looks
like this:
\begin{equation*}
  \lim_{\Delta x\rightarrow 0} \sum_{k=1}^n f(x_k)\Delta x
\end{equation*}
Leibniz invented the following expressive, versatile, and useful notation for this limit:
\begin{equation*}
  \int_a^b f(x) \der x
\end{equation*}
The symbol $\int$ is an ``S'' that's been stretched like taffy.
It stands for ``sum,'' just as the sigma, $\Sigma$,
stands for ``sum.'' But we think of $\int$ as meaning a \emph{smooth} sum, whose graphical
representation is the area under a smooth curve rather than under a staircase. Notice how the shape
of $\int$ is smooth. Like the $k$ in the sigma notation, the $x$ in this example is a dummy variable.
Therefore $\int_a^b f(x) \der x$ means exactly the same thing as $\int_a^b f(s) \der s$. The
dummy variable inside an integral is referred to as a variable of integration, and has no
meaning outside the integral. One of the reasons for writing the
$\der x$ is that it states what we're integrating with respect to.


\begin{eg}{A rectangle}\label{eg:riemann-rectangle-area}
\egquestion Evaluate
\begin{equation*}
  \int_0^4 1\:\der x \qquad .
\end{equation*}

\eganswer The graph of this function is a rectangle with height 1 and width 4.
A rectangle is a shape that can be sliced up into thin, vertical slices that are
also rectangles, and this is what any Riemann-sum approximation to this integral
will look like. The approximations aren't really approximations at all. Every
Riemann sum has an area of 4, so the limit occurring in the definition of the
integral is 4. This is of course the correct result for the area of this rectangle.
\end{eg}

\begin{eg}{Leibniz notation for the area of a triangle}\label{eg:leibniz-triangle-area}
In example \ref{eg:riemann-triangle-area}, we integrated the function $f(x)=x$ from $x=0$ to 1, and
found that it was 1/2. In Leibniz notation, the result is written like this:
\begin{equation*}
  \int_0^1 x\:\der x = \frac{1}{2}
\end{equation*}
It makes no difference if we notate this instead with $s$ as the variable of integration:
\begin{equation*}
  \int_0^1 s\:\der s = \frac{1}{2}
\end{equation*}
\end{eg}

We defined the Leibniz notation as simply a notation for a certain limit, but we can think of
it conceptually as a sum with infinitely many terms. That is, we make a Riemann sum with
infinitely many rectangles. Normally if you added up an infinite
number of things, you would expect to get an infinite result. But remember, each of these rectangles
is infinitely skinny. We think of $\der x$ as being the infinitely small width, so that the area
$f(x)\der x$ is infinitely small. We're therefore adding an infinite number of things, each of which
is infinitely small, so that the result can be finite. Recall that, as discussed in section
\ref{sec:safe-handling-of-dx}, p.~\pageref{sec:safe-handling-of-dx}, the real number system doesn't
have infinitely big or infinitely small numbers; however, if we handle our infinities
according to the simple rules given
in that section, nothing bad happens. Historically, these rules weren't clear, and practitioners just
knew that if they did their work according to certain methods, the Leibniz notation never led
to the wrong result. This confusion was definitively cleared up around 1965, but many mathematicians
have been influenced by the historical uneasiness about the Leibniz notation, so they prefer to think
of $\int\ldots\der x$ purely as a shorthand notation for a limit. This is a matter of taste. Those who prefer
to think of it only as a shorthand will consider the $\der x$ inside the integral to nothing
more than punctuation, like the period at the end of a sentence. From this point of view, its
only job is to tell us what the dummy variable is, i.e., what we're integrating with respect to.
None of these doubts about the Leibniz notation were ever influential among scientists and engineers;
they picked up the notation enthusiastically in the 1680's and continue using it, exclusively and
unmodified, to this day.

\begin{eg}{Moving the $\der x$ around}
One of the rules in section \ref{sec:safe-handling-of-dx} was that we were allowed to manipulate
differentials such as $\der x$ using any of the elementary axioms of the real numbers
(section \ref{sec:elementary-reals}, p.~\pageref{sec:elementary-reals}). One of these axioms is
that multiplication is commutative, $uv=vu$. Therefore the integral in example
\ref{eg:leibniz-triangle-area} on p.~\pageref{eg:leibniz-triangle-area} can be written in either
of the following equivalent ways:
\begin{equation*}
  \int_0^1 x\:\der x = \frac{1}{2}   \qquad    \int_0^1 \der x \: x = \frac{1}{2}
\end{equation*}
Similarly, all of the following are the same integral:
\begin{equation*}
  \int_1^2 \frac{1}{x}\:\der x = \int_1^2 \der x\:\frac{1}{x} = \int_1^2 \frac{\der x}{x}
\end{equation*}
Most people would write it with the $\der x$ on top, which makes it more compact.
\end{eg}

\begin{eg}{The integral of \ldots what?}\label{eg:integral-of-what}
How should we interpret this expression?
\begin{equation*}
  \int_0^4 \der x
\end{equation*}
There doesn't seem to be any function written inside the integral, so what is it that
we're integrating? One of the elementary axioms of the real numbers
(section \ref{sec:elementary-reals}, p.~\pageref{sec:elementary-reals}) is that 1 is the
multiplicative identity, i.e., $1u=u$ for any number $u$. As discussed in section
\ref{sec:safe-handling-of-dx}, the elementary axioms also apply to differentials. 
Therefore it's valid to rewrite our integral as follows.
\begin{equation*}
  \int_0^4 1 \der x
\end{equation*}
The function we're integrating is 1, which makes this the same integral as the one
in example \ref{eg:riemann-rectangle-area} on p.~\pageref{eg:riemann-rectangle-area}.
The result is 4.

Another way of interpreting the original form of the integral is that $\der x$ means
``a little bit of $x$,'' so that the integral expresses the idea of letting $x$ change
from 0 to 4, and adding up all the little changes in $x$. Clearly the sum of all the
little changes will be the total change, which is 4.
\end{eg}

Another nice feature of the Leibniz notation is that it makes the units come out right.
Consider our earlier example of the town dump. Suppose that the rate of garbage
production is given by a function $p(t)$, where $t$ is in units of years
and $p$ in tons per year. Then the amount of garbage accumulated at the town dump
from year $a$ to year $b$ is given by
\begin{equation*}
  \int_a^b p(t)\:\der t \qquad .
\end{equation*}
The integral sign $\int$ is a kind of sum, and the units of a sum are the same
as the units of each term. Since $\der$ means ``a little bit of \ldots,''
$\der t$ stands for a little bit of time, and it therefore also has units of years.
The units of the terms in the sum are
\begin{equation*}
  \frac{\text{tons}}{\text{year}} \times \text{years} = \text{tons} \qquad ,
\end{equation*}
which makes sense.

We can now see three independent reasons why it would be wrong to write an integral
like $\int_0^1 x^2$ rather than $\int_0^1 x^2\:\der x$, with the $\der x$:
\begin{enumerate}
  \item If $x$ has units, then the expression without the $\der x$ has the wrong units.
  \item It would be a sum of infinitely many numbers, each of them finite, so it would probably be infinite.
  \item If we don't write the $\der x$, we haven't stated what we're integrating with respect to.
\end{enumerate}
  <% end_sec('integral-leibniz') %>
  <% begin_sec("Integrating discontinuous functions",nil,'integral-discontinuous') %>


riemann-triangle-sample-right


In general, a Riemann sum need
not have equal subdivisions (the rectangles could be of unequal widths
$\Delta x_k$), and the
points $x_k$ at which we sample the function need not be at the center of each
interval.
For essentially all functions encountered in practical applications, this makes
no difference. As long as we force all the widths to get smaller, and sample
the function somewhere within each interval, we get the same answer. 
We are free, for example, to sample the
function at the left or right side of each subinterval rather than at the center.
The only case where this choice would matter would be for a function that was
spectacularly badly behaved: one that was discontinuous at infinitely
many points within the interval $[a,b]$. This is addressed
in box \figref{riemann-integral}.


Let $f$ be the real function defined such that $f(x)=0$ if $x$ is rational, and
$f(x)=1$ otherwise. Such a function can never, for example, be a result of any
physical process or any measurement, since measurements can't distinguish rational
numbers from irrational ones. If we integrate this function
from $0$ to $1$, 
using Riemann sums with equal subintervals, sampled at their centers, we get $0$
because all the $x_k$'s are rational. But this is in some sense the wrong answer,
since ``most'' real numbers are irrational, so $f$ is ``usually'' equal to 1, not 0.

For these reasons, Riemann defined an integral, now known as the Riemann integral,
as follows. Suppose we have a number $I$ such that
for every $\varepsilon >0$, there exists a $\delta>0$ such that
$|R -I|<\varepsilon$ for \emph{every} Riemann sum all of whose intervals have width $\Delta
  x_k<\delta$ with any arbitrary choice of sample points $x_1$, \dots , $x_n$.
Then $I$ is the Riemann integral of the function. For the function $f$ defined
above, the Riemann integral is undefined, as it should be.
  <% end_sec('integral-discontinuous') %>

<% end_sec('definite-integral') %>

<% begin_sec("The fundamental theorem of calculus",4,'fundamental-theorem') %>
  <% begin_sec("A connection between the derivative and the integral",nil,'connect-derivative-and-integral') %>
We've already seen some clear indications of a link between derivatives and integrals.
A derivative is a rate of change, and an integral measures the accumulation of change.
Let's say for concreteness that we're talking about functions of time.
If a function $A$ tells us the rate at which function $B$ changes, then $B$ tells us
how the rate of change measured by $A$ has accumulated over time. That is, it seems
clear conceptually that the integral and the derivative are inverse operations: operations
that undo each other, in the same way that subtraction undoes addition, or a square
root undoes a square.
<% marg(0) %>
<%
  fig(
    'garbage-spreadsheet-bitmap',
    %q{Columns A and B in the spreadsheet relate to each other approximately as derivative and integral.}
  )  
%>
<% end_marg %>

Figure \figref{garbage-spreadsheet-bitmap} shows this in the context of discrete rather than
continuous functions. Column A shows how many tons of garbage are sent to the town dump per year.
It is the rate of change of the pile at the dump, which is given in column B. The population
is growing, so column A is not constant. Presumably one of these columns was typed into the
spreadsheet from data collected by the town, but we can't tell from looking at the spreadsheet
which one it was. It's possible that the raw data was column A, in which case column B would
have been constructed by telling the spreadsheet software to calculate a running sum based on A.
The running sum of a discrete function is conceptually similar to the integral of a continuous
one, so we can say that in some loose sense that B is the integral of A. On the other hand,
it's possible that the raw data was column B: a municipal employee has been going out to the dump at yearly
intervals and measuring how big the pile of trash was. Column A would then have been calculated from B
by taking differences of successive years. This is conceptually similar to saying that A is the
derivative of B.
  <% end_sec('connect-derivative-and-integral') %>
  <% begin_sec("What the fundamental theorem says",nil,'fundamental-theorem-statement') %>

\begin{theorem}[The fundamental theorem of calculus]
  Let $f$ be a function defined on the interval $[a,b]$, and let $f$ be differentiable
  on that interval. Then
  \begin{equation}
    \label{eqn:fundamental-theorem}
    \int_a^b \frac{\der f}{\der x} \der x = f(b) - f(a) \qquad .
  \end{equation}
\end{theorem}

On the left-hand side, we have taken a function, differentiated it, and
then integrated it. The right-hand side is a simple expression involving the
original function, i.e., in some sense the integration has undone the
differentation, and we are left with the same function we started with.
<% marg(0) %>
<%
  fig(
    'garbage-spreadsheet-different-initial-conditions',
    %q{The initial amount of garbage is 1000 tons rather than zero.}
  )  
%>
<% end_marg %>

To see why the right-hand side contains a difference of two values of
$f$, consider figure \figref{garbage-spreadsheet-different-initial-conditions},
which is a modified version of \figref{garbage-spreadsheet-bitmap}. What's changed
is that rather than starting out empty in the first year, in this version of
history the dump started out with 1000 tons of garbage already in it.
This alteration of column B, however, has no effect on column A. For example,
the subtraction $1015-1010$ gives the same result as $15-10$. 
The fundamental theorem tells us that we can make a ``round trip'' by computing column
A from column B using differences, and then reconstructing column B again by taking a running sum.
But the round trip isn't perfect (cf.~figure
\figref{chinese}). Some information is lost, because given column A,
we can't tell whether the version of column B we should reconstruct is the one in
figure \figref{garbage-spreadsheet-bitmap}, the one in 
\figref{garbage-spreadsheet-different-initial-conditions}, or some other version that differs
from them by some other additive constant. What we \emph{can} tell is that the \emph{difference}
between the initial and final cells of column B must have been 28, which is the sum of
column A.
<% marg(100) %>
<%
  fig(
    'chinese',
    %q{After translation by a computer from English to Chinese, and then back to English, 
       the original sentence is not quite the same. By analogy, the fundamental theorem tells us that
       if we differentiate, then integrate, we cannot quite recover the original
       function: we lose any information that amounts to an over-all additive constant.}
  )  
%>
<% end_marg %>

In terms of continuous functions rather
than discrete ones, adding a constant onto $f$ doesn't change the derivative $\der f/\der x$.
Therefore the left-hand side of the fundamental theorem can never tell us the \emph{value} of
$f$ but only the \emph{difference in values} between $x=a$ and $x=b$.

  <% end_sec('fundamental-theorem-statement') %>
  <% begin_sec("A pseudo-proof",nil,'fundamental-theorem-pseudo-proof') %>

We've seen examples before in which the Leibniz notation makes certain facts about calculus
seem so obvious that they don't seem to need any further proof. This happens, for
example, if we rewrite the chain
rule as $\der z/\der x = (\der z/\der y)(\der y/\der x)$, which makes it seem like a simple
fact about algebra; but this is not quite a rigorous proof for the reasons explained
in example \ref{eg:chain-rule-not-quite-proof}, p.~\pageref{eg:chain-rule-not-quite-proof}.
It's a ``pseudo-proof,'' but that's not necessarily a bad thing. Pseudo-proofs can be good.
The pseudo-proof helps
us to understand why the result makes sense, and it can, if we wish, serve as the backbone of a more
rigorous proof.

We will give a real proof of the fundamental theorem in section
\ref{subsec:fundamental-theorem-proof}, p.~\pageref{subsec:fundamental-theorem-proof},
but let's warm up with the pseudo-proof, which is pretty simple. We start with a statement of the
result,
\begin{equation}
    \int_a^b \frac{\der f}{\der x} \der x \stackrel{?}{=} f(b) - f(a) \qquad ,
\end{equation}
with the question mark above the equals sign to show that this is what we are hoping to prove.
For the same reasons as in example \ref{eg:chain-rule-not-quite-proof}
on p.~\pageref{eg:chain-rule-not-quite-proof}, it is not quite valid to cancel the factors of
$\der x$, but we'll do it anyway because this is only meant to be a pseudo-proof.
\begin{equation}\label{eqn:fund-thm-pseudo-proof-2}
    \int_{f(a)}^{f(b)} \der f \stackrel{?}{=} f(b) - f(a) 
\end{equation}
We can interpret the symbol $\der f$ as ``a little bit of $f$,'' so that the left-hand side
is the sum of many very small changes in $f$. The limits of integration are now stated in terms
of the values of $f$, since $f$ is now the variable of integration, not $x$. (It's true, but
not as obvious, that this is equally valid regardless of whether $f$ is always increasing or
always decreasing. If $f$ goes up and then comes back down, we could, for example, have
$f(a)=f(b)$, so that the upper and lower limits of integration were the same.)

It's clearly
reasonable now to hope that we can make the left-hand side of equation \eqref{eqn:fund-thm-pseudo-proof-2} equal
the right. The left-hand side
says that we add up many small changes in the variable $f$. The right-hand side is simply the
total accumulated change in $f$. To see this a little more explicitly, let's insert
a factor of 1 inside the integral, as in example \ref{eg:integral-of-what}, p.~\pageref{eg:integral-of-what}.
\begin{equation}\label{eqn:fund-thm-pseudo-proof-3}
    \int_{f(a)}^{f(b)} 1\cdot\der f = f(b) - f(a) 
\end{equation}
As in that example, this integral represents the area of a rectangle. The rectangle has width
$f(b)-f(a)$ and height 1, so its area is $f(b)-f(a)$, and the equation holds.

  <% end_sec('fundamental-theorem-pseudo-proof') %>

  <% begin_sec("A real proof",nil,'fundamental-theorem-proof') %>
In proving the fundamental theorem of calculus,
  \begin{equation}
    \int_a^b f'(x) \der x = f(b) - f(a) \qquad ,
  \end{equation}
we use the definition of the integral in terms of a Riemann sum, in which
the interval $[a,b]$ into $n$ equal subintervals $[x_i,x_{i+1}]$, where $i=1$, 2, \ldots $n-1$.
However, rather than restricting ourselves to sampling at the center of each subinterval,
we assume that we have the freedom to choose any sample
point $s_i$ within each subinterval. This is equivalent to
assuming that the functions $f$ and $f'$ are not horribly badly behaved, so that our definition of the integral
on p.~\pageref{integral-defined}
is equivalent to the Riemann integral defined in box \figref{riemann-integral}.
We now apply the mean value theorem to each subinterval, and choose $s_i$ to be the point for which
\begin{equation*}
  f'(s_i) = \frac{\Delta f_i}{\Delta x} \qquad ,
\end{equation*}
where $\Delta f_i=f(x_{i+1})-f(x_i)$ and $\Delta x=x_{i+1}-x_i$.
This can be rearranged to give
\begin{equation*}
  \Delta f_i = f'(s_i)\Delta x \qquad .
\end{equation*}
Adding these up, we have
\begin{equation*}
  f(b)-f(a) = \sum_{i=1}^n f'(s_i)\Delta x \qquad .
\end{equation*}
This tells us that by an appropriate choice of the sample points, we can make \emph{every} Riemann
sum, for \emph{every} $n$ produce the result claimed by the fundamental theorem. It therefore
follows that the limit that defines the integral has the value claimed by the theorem.\myqed

  <% end_sec('fundamental-theorem-proof') %>

  <% begin_sec("Using the fundamental theorem to integrate; the indefinite integral",nil,'using-fundamental-theorem') %>
The fundamental theorem says this:
\begin{equation*}
  \int_a^b f'(x) \der x = f(b) - f(a) \qquad .
\end{equation*}
In some examples, this gives us a tricky way to evaluate an integral exactly without having to muck
around with Riemann sums. Consider the integral
\begin{equation*}
  \int_0^1 x\:\der x \qquad ,
\end{equation*}
whose geometrical interpretation is the area of a triangle and whose value we showed to be
$1/2$  using Riemann sums in
example \ref{eg:riemann-triangle-area}, p.~\pageref{eg:riemann-triangle-area}.
The function we're integrating is $x$, but what if we could find a function $f$
whose derivative was $x$? ---
\begin{equation*}
  f'(x) = x
\end{equation*}
The fundamental theorem would then immediately tell us the result of the integral.
The function $f$ is called an \emph{antiderivative} of the function $x$.
Although there are various tricks and methods for finding antiderivatives, in general
the only way to find them is to guess and check. One way to approach this one is to
think of $x$ as $x^1$. We know that when we differentiate a power, the power rule
tells us to knock down the exponent by one. That makes it reasonable to guess
something like $x^2$ as an antiderivative of $x$. Checking our guess, we find that
it was almost, but not quite, right:
\begin{equation*}
  f(x)=x^2 \implies f'(x)=2x \qquad \text{[not quite what we wanted]}
\end{equation*}
We wanted the derivative to be $x$, but we got $2x$. This is easily fixed by
halving our guess:
\begin{equation*}
  f(x)=\frac{1}{2}x^2 \implies f'(x)=x
\end{equation*}
The function $\frac{1}{2}x^2$ is an antiderivative of $x$. Therefore by the fundamental
theorem we have
\begin{align*}
  \int_0^1 x\: \der x &= f(1) - f(0) \\ 
         &= \frac{1}{2}1^2-\frac{1}{2}0^2 \\
         &= \frac{1}{2} \qquad .
\end{align*}
This is the same result that we obtained earlier and with much more labor using Riemann sums.

Because this technique is so frequently used,
expressions of the form $f(b)-f(a)$ are very common, and
various abbreviations have been invented.  We will abbreviate
\[
f(b)-f(a) \stackrel{\text{def}}{=} \bigl. f(x)\bigr]_{x=a}^b =
\bigl.f(x)\bigr]_a^b \qquad .
\]

Any time we have an antiderivative, we can produce other antiderivatives by adding a constant.
For example, all of the following are antiderivatives of the constant function 7 with respect to $x$:
\begin{equation*}
  7x \qquad 7x+1 \qquad 7x-42
\end{equation*}
Differentiating any one of these with respect to $x$ gives 7. 

An antiderivative is more commonly referred to as an indefinite integral --- as opposed to the kind
of integral we've been talking about up until now, which is called a definite integral.
The Leibniz notation for an indefinite integral is an integral sign without any upper or lower
limits of integration. For example,
\begin{equation*}
  \int x\:\der x = \frac{1}{2}x^2 + c \qquad ,
\end{equation*}
where $c$ is any constant. One way of understanding this notation is that both sides of this equals
sign represent a certain \emph{solution set} --- the set of all functions whose derivative equals $x$.
Similarly, when we write
\begin{equation*}
  \sqrt{4} = \pm 2 \qquad ,
\end{equation*}
we could say that both sides of the equation represent the solution set $\{-2,2\}$ of the equation
$x^2=4$.

antiderivative of symbolic const

example using Newton's second law with constant force

square root analogy

Leibniz notation

show proof of fund thm in figure, upper and lower saw teeth canceling term by term

figure showing multiple antiderivatives as vertical shifts

  <% end_sec('using-fundamental-theorem') %>

<% end_sec('fundamental-theorem') %>


<% end_chapter %>
