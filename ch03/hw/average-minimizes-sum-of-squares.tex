Suppose we have a list of numbers $x_1,\ldots x_n$, and we wish to find some number $q$ that is as close as possible
to as many of the $x_i$ as possible. To make this a mathematically precise goal, we need to define some numerical
measure of this closeness. Suppose we let $h=(x_1-q)^2+\ldots+(x_n-q)^2$, which can also be notated using $\Sigma$, uppercase Greek
sigma, as $h=\sum_{i=1}^n (x_i-q)^2$. Then minimizing $h$ can be used as a definition of optimal closeness.
(Why would we not want to use $h=\sum_{i=1}^n (x_i-q)$?) Prove that the value of $q$ that extremizes $h$ is
the average of the $x_i$, and use the second derivative test to prove that the extremum is a minimum.
