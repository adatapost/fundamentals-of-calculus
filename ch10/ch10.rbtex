%%chapter%% 10
<%
  require "./scripts/eruby_util.rb"
%>

<%
  chapter(
    '10',
    %q{Applications of the integral},
    'ch:integration-applications'
  )
%>

<% begin_sec("Probability",nil,'probability') %>
  <% begin_sec("Introduction to probability",nil,'probability-intro') %>
    <% begin_sec("Measurement of probabilities",nil,'probability-meas') %>
Defining randomness is a difficult problem, tied up with classical philosophical
issues such as determinism and free will. Mathematicians sidestep this question
by simply using numbers between 0 and 1 to represent probabilities. A zero probability represents
an event that can't happen, a probability of 1 an event than is guaranteed to happen.
In between we have things that might or might not happen. A
flipped coin comes up heads with probability 1/2.
    <% end_sec('probability-meas') %>
    <% begin_sec("Statistical independence",nil,'independence') %>
<% marg(30) %>
<%
  fig(
    'slot-machine',
    %q{%
      The probability that one wheel on the slot machine will give a cherry is 1/10. If the three
      probabilities are independent, then the
      probability that all three wheels will give cherries is $1/10\times1/10\times1/10$.
    }
  )
%>
\spacebetweenfigs
<%
  fig(
    'globe',
    %q{%
      The earth's surface is 30\% land and 70\% water. If we spin a globe and pick a random point,
      the probabilities of hitting land and water are 0.3 and 0.7. Normalization requires that these
      two probabilities add up to 1.
    }
  )
%>
<% end_marg %>

When ordinary people say that an event is ``random,'' they usually mean not just
that it has a probability greater than 0 and less than 1, but also that it can't be
predicted, because there is no way of finding a connection with another event that caused it.
This lack of connection is considered by mathematicians to be separate from randomness itself,
and is defined as follows.

\begin{lessimportant}[Definition of statistical independence]
Events A and B are said to be statistically independent if
the probability that they will both happen is given by the product of
the two probabilities.
\end{lessimportant}

Events can be random but not independent. It might or might not rain tomorrow, and there might or
might not be a forest fire. These events are both random, but they are not independent, since rain
makes fire less likely.

    <% end_sec('independence') %>
    <% begin_sec("Normalization",nil,'normalization') %>

Suppose that we are able to exhaustively list all of the possible outcomes A, B, C, \ldots of some
situation, and that these outcomes are mutually exclusive. Then exactly one of these outcomes must
occur, so the probabilities must add up to one. For example, suppose that we flip a coin, and A is
the event that the coin comes up heads, B tails. Then $P_A+P_B=\frac{1}{2}+\frac{1}{2}=1$. This
property is called \emph{normalization}.\index{normalization}

    <% end_sec('normalization') %>


  <% end_sec('probability-intro') %>
  <% begin_sec("Continuous random variables",nil,'continuous-random-variables') %>
When numerical values are assigned to outcomes, the result is called a \emph{random variable}.
The sum of the rolls of two dice is a random variable, and we can assign probabilities to
the different results. For example, the probability of rolling 2 is $1/36$, since the probability
of getting a 1 on the first die is $1/6$, and similarly for the second die. All of the relevant
information about probabilities can be summarized by the discrete function shown in figure \figref{two-dice}.
<% marg(300) %>
<%
  fig(
    'dice',
    %q{%
      The sum of the two dice is a random variable with possible values running from 2 to 12.
    }
  )
%>
\spacebetweenfigs
<%
  fig(
    'two-dice',
    %q{%
      The histogram shows the probabilities of the various outcomes when rolling two dice.
    }
  )
%>
\spacebetweenfigs
<%
  fig(
    'human-height',
    %q{%
      A probability distribution for height of human adults. (Not real data.)
    }
  )
%>
<% end_marg %>

But when a random variable is continuous rather than discrete, we usually cannot make
a useful graph of the probabilities, because the probability of any particular real number
is typically zero. For example, there is zero probability that a person's height $h$ will be
160 cm, since there are
infinitely many possible results that are close to that value, such as
159.999999999999996876876587658465436 cm. What \emph{is} useful to talk about is
the probability that $h$ will be \emph{less than} a certain value. The probability of
$h<160\ \zu{cm}$ is about 0.5. In general, we define the \emph{cumulative probability distribution}
$P(x)$ of a random variable to be the probability that the variable is less than or equal to $x$.
We can then define the \emph{probability distribution} of the variable to be
\begin{equation}
  D(x) = P'(x) \qquad .
\end{equation}
Figure \figref{human-height} shows an approximate probability distribution for human height.
Suppose we want to know the probability that our random variable lies within the range from $a$ to
$b$. This is $P(b)-P(a)$. By the fundamental theorem of calculus, this can be calculated from
the definite integral of the distribution,
\begin{equation}
  P(b)-P(a) = \int_a^b D(x)\:\der x \qquad .
\end{equation}
That is, areas under the probability distribution correspond to probabilities. If the random
variable has some units, say centimeters, then the units of the probability distribution $D$ are the
inverse of those units, e.g., $\zu{cm}^{-1}$ in our example. In this example, $D$ can be
interpreted as the probability \emph{per centimeter}. A \emph{uniform} distribution is one
for which $D$ is a constant throughout the range of possible values of $x$.

If there are definite lower and upper limits $L$ and $U$ for the possible values of the random
variable, then normalization requires that
\begin{equation}
  1 = \int_L^U D(x)\:\der x \qquad .
\end{equation}

The average $\bar{x}$ of a variable that takes on one of two discrete values with equal probability is
$(x_1+x_2)/2$, which is the same as $x_1P_1+x_2P_2$. Generalizing this to a continuous random
variable, we have
\begin{equation}\label{eqn:average-defined}
  \bar{x} = \int_L^U x D(x)\:\der x \qquad .
\end{equation}
The average is also known as the \emph{mean}, \emph{expectation}, or the \emph{expected value} of $x$.

The standard deviation $\sigma_x$ of a random variable $x$ is a measure of how much it varies around
its average value. The symbol $\sigma$ is the lowercase Greek ``sigma.'' (Recall that uppercase
sigma is $\Sigma$.) The standard deviation of a continuous random variable is defined by
\begin{equation}
  \sigma_x = \sqrt{\int_L^U (x-\bar{x})^2 D(x)\:\der x} \qquad .
\end{equation}

It often happens that one random variable $y$ is defined by some function of some other
random variable $x$. In an experiment, for example, one may measure $x$ directly, and the
value of $x$ is a random variable because of the finite precision of the measurement. If one
calculates the result of the experiment using some function $y(x)$, then the result is also
a random variable. Let the corresponding probability distributions and
cumulative probability distributions be $D_x$, $D_y$, and let $P$ be the cumulative probability
for a given $x$ or $y$. Then $D_y$ can be
determined from $D_x$ by the chain rule:
\begin{align*}
  D_y &= \frac{\der P}{\der y} \qquad \text{[definition of $D$]} \\
      &= \frac{\der P}{\der x} \cdot \frac{\der x}{\der y} \qquad \text{[chain rule]} \\
      &= D_x \cdot \frac{\der x}{\der y} \qquad \text{[definition of $D$]} \\
      &= \frac{D_x}{y'(x)} \qquad \text{[derivative of the inverse of a function]}
\end{align*}

\begin{eg}{A random goblin}
Often in computer simulations or games one wants to produce a random number with some
desired distribution. For example, in a fantasy adventure game, we might wish to generate
an opponent such as a goblin whose strength statistic $y$ is distributed according to some
bell-shaped curve $D_y$ with a given mean and standard deviation. The random number generators
supplied in computer programming libraries usually output a number $x$ with a uniform distribution
from 0 to 1, so that $D_x=1$. We then have $y'(x)=1/D_y$. Integrating both sides of this equation
allows us to find a function $y(x)$ that determines the strength of the goblin.
\end{eg}

  <% end_sec('continuous-random-variables') %>
<% end_sec('probability') %>

<% begin_sec("Economics",4,'economics') %>
<% marginbox(0,'economics-applications','Applications to economics',{},
%q~
The following is an index of applications of calculus to economics
that occur throughout this book.

\noindent\begin{tabular}{lp{16mm}p{15mm}}
\emph{p.} & \emph{application} & \\\\
\pageref{eg:indifference-curve} & marginal rate of substitution & derivative \\\\
\pageref{eg:order-quantity} & economic order quantity & extrema \\\\
\pageref{subsubsec:laffer-curve} & the Laffer curve & Rolle's theorem \\\\
\pageref{eg:supply-and-demand} & supply and demand & intermediate value theorem 
\end{tabular}
      ~
   )
%>
In 1882, at the age of 46, William Stanley Jevons went swimming in the ocean and drowned.
As a pioneer of classical economics,
Jevons developed mathematical models that treated
humans as rational actors seeking to maximize their happiness.
His choice to go swimming that day was presumably based on the fact that swimming would
cause him to be happy, and on the conscious or unconscious expectation that his risk of death would be low.
But how do we define ``rational'' and ``happiness'' mathematically? 
Believe it or not, economists did produce 
definitions of these ideas, but in the process the word ``happiness'' changed to ``utility,''
and the concepts morphed into forms that were very different from their original meanings.
They are central to modern economics.

A 1947 paper by John von Neumann and Oskar Morgenstern (VNM) introduced four axioms describing
rationality, which I'll describe here in English rather than equations:
\begin{enumerate}
\item Preferences are consistent.
\item Preferences are transitive: if you like outcome A more than B, and B more than C, then you like
       A more than C.
\item No outcome is infinitely good or bad. For example, if Jevons had believed that death was infinitely
       bad, he might have been unwilling to accept \emph{any} risk of drowning.
\item A preference for A over B holds regardless of whether some other outcome exists. For example,
       if you like Bach more than bebop, this is true regardless of whether it rains.
\end{enumerate}
VNM were able to prove that if these axioms hold, it is possible to assign
a real number $u(x)$, called the utility function,
to any outcome $x$ such that a rational actor always maximizes the expected
value of $u$ as defined by equation \eqref{eqn:average-defined}, p.~\pageref{eqn:average-defined}.

Although I've described this in terms of human preferences, the axioms may fail for humans or hold
for non-humans. It only matters if the actor behaves \emph{as if} it were acting rationally, as defined
by the axioms. For example,  Milton Friedman writes:\footnote{``Essays
in positive economics,'' University of Chicago Press (1953), 1970, p.~3}

\begin{quote}
I suggest the hypothesis that the leaves [on a tree] are positioned as if each leaf deliberately sought
 to maximize the amount of sunlight it receives, given the position of its neighbors, as if it
 knew the physical laws determining the amount of sunlight that would be received in various positions and
 could move rapidly or instantaneously from any one position to any other desired and unoccupied position.
\end{quote}

\noindent Economist Daniel Kahneman, on the other hand, won the Nobel prize for his work showing
that human beings often violate the VNM definition of rationality, but
in ways that can be described scientifically. For instance, he showed in experiments that subjects
were willing to pay one price for a trinket such as a mug, but that if they were
given the mug, they demanded a different and systematically higher price to sell it. This violates axiom 1.
Axiom 1 was implicitly assumed in the description of the indifference curve in example
\ref{eg:indifference-curve}, p.~\pageref{eg:indifference-curve}.

%%graph%% lottery func=1-exp(-x) format=eps xlo=-1 xhi=1 ylo=-2 yhi=1 y=u ytic_spacing=1

<% marg(-20) %>
<%
  fig(
    'lottery',
    %q{%
      The utility function of example \ref{eg:lottery}.
    }
  )
%>
<% end_marg %>


\begin{eg}{Playing the lottery}\label{eg:lottery}
Joe is broke and homeless. He currently has an amount of money $x=0$. Joe's utility function is given
by
\begin{equation*}
  1-e^{-x} \qquad ,
\end{equation*}
where $x$ is in some appropriate units such as thousands of dollars. The shape of this function is
shown in figure \figref{lottery}. It is concave down, which is a feature that is almost always
realistic for a utility function that depends on how much money someone has. The idea is that the more
money you have, the less you care about getting more money. If
Joe is broke and gains \$10, he's really happy, whereas if Bill Gates saw a \$10 bill on the sidewalk,
he probably wouldn't bother to bend over and pick it up.

Joe knows of a lottery in which each player receives a random amount of money
uniformly distributed on the interval from 0 to 1. What price $L$ should Joe be willing to pay for
the lottery ticket, if he has the opportunity to borrow the price from his mother?

If Joe enters and receives the minimum payout of 0, he will have $x=-L$, i.e., he will
be in debt to his mother for the price of the ticket and have nothing to show for it. If he
gets the maximum reward of 1, he will have $x=1-L$. Since this interval has width 1,
and the result is uniformly distributed, normalization requires that $D(x)=1$ within the interval.
We find
his expected utility.
\begin{align*}
  \bar{u} &= \int_{-L}^{1-L} u(x)D(x)\:\der x = \int_{-L}^{1-L} (1-e^{-x})\:\der x \\
          &= \left.x+e^{-x}\right]_{-L}^{1-L} = 1-\left(1-e^{-1}\right)e^L
\end{align*}
Joe's current utility function is $u(0)=0$, so it is rational for him to pay any amount $L$
that gives him $\bar{u}>0$. The result is
\begin{equation*}
  L = -\ln\left(1-e^{-1}\right) \approx 0.46 \qquad .
\end{equation*}
If Joe's utility function had been $u(x)=x$, then he should have been willing to pay 0.5 units
of money for a chance to win between 0 and 1 units. But because his utility function is nonlinear,
he is willing to pay less than that; he is risk-averse.
\end{eg}

<% end_sec('economics') %>
